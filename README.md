# Homebox Companion

AI-powered companion app for [Homebox](https://github.com/sysadminsmedia/homebox) inventory management.

Take a photo of your stuff, and let AI identify and catalog items directly into your Homebox instance. Perfect for quickly inventorying a room, shelf, or collection.

## What It Does

Homebox Companion streamlines the process of adding items to your home inventory:

```mermaid
flowchart LR
    A[üîê Login<br/>Homebox] --> B[üìç Select<br/>Location]
    B --> C[üì∏ Capture<br/>Photos]
    C --> D[‚úèÔ∏è Review &<br/>Edit Items]
    D --> E[‚úÖ Submit to<br/>Homebox]
    
    B -.-> B1[/Hierarchical<br/>location tree/]
    C -.-> C1[/AI analyzes with<br/>OpenAI GPT-5/]
    D -.-> D1[/Edit names,<br/>quantities, labels/]
```

1. **Login** ‚Äì Authenticate with your existing Homebox credentials
2. **Select Location** ‚Äì Navigate your hierarchical location tree (e.g., Home ‚Üí Garage ‚Üí Toolbox)
3. **Capture Photos** ‚Äì Take or upload photos of items (supports multiple photos per item)
4. **AI Detection** ‚Äì OpenAI vision identifies items, quantities, and metadata
5. **Review & Edit** ‚Äì Adjust AI suggestions, merge items, or ask AI to correct mistakes
6. **Submit** ‚Äì Items are created in your Homebox inventory with photos attached

## Features

### Core Features
- **Photo-based Detection** ‚Äì Upload or capture photos of items from your device
- **AI Vision Analysis** ‚Äì Uses OpenAI GPT-5 to identify items in images
- **Smart Labeling** ‚Äì Automatically suggests labels from your existing Homebox labels
- **Hierarchical Locations** ‚Äì Navigate and select from your full location tree
- **Batch Processing** ‚Äì Analyze multiple photos in parallel for faster processing
- **Mobile-First UI** ‚Äì Designed for phones (works great on desktop too)

### AI Capabilities
- **Multi-Image Analysis** ‚Äì Upload multiple photos of the same item taken from different angles or distances to improve detection accuracy. You can also include close-ups of labels, serial numbers, receipts, and other identifying details to enhance recognition.
- **Extended Fields Detection** ‚Äì Automatically extracts manufacturer, model number, serial number, purchase price when visible
- **Single-Item Mode** ‚Äì Force AI to treat everything in a photo as one item (useful for sets/kits)
- **AI Corrections** ‚Äì Tell the AI what it got wrong and it will re-analyze with your feedback
- **Label Matching** ‚Äì AI suggests appropriate labels from your existing Homebox label library

### Review Features
- **Edit Detected Items** ‚Äì Modify names, quantities, descriptions before saving
- **Custom Thumbnails** ‚Äì Crop and select the best thumbnail for each item
- **Skip or Confirm** ‚Äì Review each detected item individually
- **Add More Photos** ‚Äì Attach additional images during review for better AI analysis

## Quick Start

### Prerequisites

- Python 3.12+
- Node.js 18+ (for frontend development)
- [uv](https://docs.astral.sh/uv/) (recommended) or pip
- An OpenAI API key ([get one here](https://platform.openai.com/api-keys))
- A Homebox instance (or use the demo server)

### Installation

```bash
# Clone the repository
git clone https://github.com/Duelion/homebox-companion.git
cd homebox-companion

# Install Python dependencies
uv sync

# Install frontend dependencies
cd frontend && npm install && cd ..
```

### Configuration

For local development, create a `.env` file:

```bash
# .env file contents
HBC_OPENAI_API_KEY=sk-your-api-key-here
HBC_HOMEBOX_URL=http://localhost:7745  # or https://your-homebox.example.com
HBC_OPENAI_MODEL=gpt-5-mini
# HBC_OPENAI_BASE_URL=http://localhost:1234/v1  # For custom OpenAI-compatible endpoints
HBC_LOG_LEVEL=INFO
```

You can also set the environment variables directly:

**Linux/macOS:**
```bash
# Required: Your OpenAI API key
export HBC_OPENAI_API_KEY="sk-your-api-key-here"

# Optional: Your Homebox URL (default: demo server)
# We automatically append /api/v1 to this URL
# Include port if your Homebox isn't behind a reverse proxy
export HBC_HOMEBOX_URL="http://192.168.1.100:7745"  # or https://your-homebox.example.com

# Optional: OpenAI model (default: gpt-5-mini)
export HBC_OPENAI_MODEL="gpt-5-mini"

# Optional: Custom OpenAI-compatible API endpoint (for local models, Azure OpenAI, etc.)
# export HBC_OPENAI_BASE_URL="http://localhost:1234/v1"

# Optional: Server configuration
export HBC_SERVER_HOST="0.0.0.0"
export HBC_SERVER_PORT="8000"

# Optional: Log level (DEBUG, INFO, WARNING, ERROR)
export HBC_LOG_LEVEL="INFO"
```

**Windows (PowerShell):**
```powershell
$env:HBC_OPENAI_API_KEY = "sk-your-api-key-here"
$env:HBC_HOMEBOX_URL = "http://192.168.1.100:7745"  # Include port if no reverse proxy
```

### Running the App

**Development (two terminals):**

```bash
# Terminal 1: Start backend API (port 8000)
uv run uvicorn server.app:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Start frontend dev server (port 5173)
cd frontend && npm run dev
```

Open `http://localhost:5173` in your browser. The Vite dev server proxies `/api` requests to the backend.

**Production (single service):**

```bash
# Build frontend to static files
cd frontend && npm run build

# Copy build output to server static directory
cp -r build/* ../server/static/
cd ..

# Start server (serves both API and frontend on port 8000)
uv run python -m server.app
```

**Docker (Recommended):**

Pull the latest image from GitHub Container Registry:

```bash
docker pull ghcr.io/duelion/homebox-companion:latest
```

Then create a `docker-compose.yml` file:

```yaml
version: "3.4"

services:
  homebox-companion:
    image: ghcr.io/duelion/homebox-companion:latest
    container_name: homebox-companion
    restart: always
    environment:
      - HBC_OPENAI_API_KEY=sk-your-api-key-here
      # Use your Homebox URL with port (e.g., http://192.168.1.100:7745)
      # Or domain if behind reverse proxy (e.g., https://homebox.example.com)
      - HBC_HOMEBOX_URL=http://192.168.1.100:7745
      - HBC_OPENAI_MODEL=gpt-5-mini
      - HBC_LOG_LEVEL=INFO
    ports:
      - 8000:8000
```

Then run:

```bash
docker compose up -d
```

**Docker Run:**

```bash
docker run -d -p 8000:8000 \
  -e HBC_OPENAI_API_KEY="sk-your-api-key-here" \
  -e HBC_HOMEBOX_URL="http://192.168.1.100:7745" \
  ghcr.io/duelion/homebox-companion:latest
```

> **Note for Docker networking:** If your Homebox instance runs on the same machine (but outside Docker), use `http://host.docker.internal:PORT` as the URL. For example, if Homebox runs on port 7745:
> ```yaml
> - HBC_HOMEBOX_URL=http://host.docker.internal:7745
> ```
> On Linux, you may need to add `--add-host=host.docker.internal:host-gateway` to the docker run command, or use `network_mode: host` in your compose file.

## Environment Variables Reference

All environment variables use the `HBC_` prefix (short for Homebox Companion).

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `HBC_OPENAI_API_KEY` | Yes | - | Your OpenAI API key |
| `HBC_HOMEBOX_URL` | No | Demo server | Your Homebox URL with port if needed, e.g., `http://192.168.1.100:7745` (we append `/api/v1` automatically) |
| `HBC_OPENAI_MODEL` | No | `gpt-5-mini` | OpenAI model for vision (`gpt-5-nano` for fastest/cheapest) |
| `HBC_OPENAI_BASE_URL` | No | - | Custom base URL for OpenAI-compatible endpoints (e.g., `http://localhost:1234/v1` for local models, or Azure OpenAI endpoint) |
| `HBC_SERVER_HOST` | No | `0.0.0.0` | Server bind address |
| `HBC_SERVER_PORT` | No | `8000` | Server port |
| `HBC_LOG_LEVEL` | No | `INFO` | Logging level |

## Using with Demo Server

For testing, you can use the Homebox demo server (this is the default if `HBC_HOMEBOX_URL` is not set):

```bash
export HBC_HOMEBOX_URL="https://demo.homebox.software"
```

Demo credentials: `demo@example.com` / `demo`

## Using Custom OpenAI-Compatible Endpoints

Homebox Companion supports any OpenAI-compatible API endpoint, including:

- **Local LLMs** (via [LM Studio](https://lmstudio.ai/), [Ollama](https://ollama.ai/), [LocalAI](https://localai.io/), etc.)
- **Azure OpenAI Service**
- **Other OpenAI-compatible providers**

### Local LLM Example (LM Studio)

```bash
# Start LM Studio with a vision-capable model (e.g., LLaVA, BakLLaVA)
# Configure LM Studio to run on port 1234 with OpenAI-compatible endpoint

export HBC_OPENAI_API_KEY="not-needed"  # Some tools require a key even if not used
export HBC_OPENAI_BASE_URL="http://localhost:1234/v1"
export HBC_OPENAI_MODEL="llava-v1.5-7b"  # Use the exact model name from LM Studio
```

### Azure OpenAI Example

```bash
export HBC_OPENAI_API_KEY="your-azure-api-key"
export HBC_OPENAI_BASE_URL="https://your-resource.openai.azure.com/openai/deployments/your-deployment"
export HBC_OPENAI_MODEL="gpt-4-vision"
```

### Docker with Custom Endpoint

```yaml
version: "3.4"

services:
  homebox-companion:
    image: ghcr.io/duelion/homebox-companion:latest
    environment:
      - HBC_OPENAI_API_KEY=not-needed
      - HBC_OPENAI_BASE_URL=http://host.docker.internal:1234/v1
      - HBC_OPENAI_MODEL=llava-v1.5-7b
      - HBC_HOMEBOX_URL=http://192.168.1.100:7745
    ports:
      - 8000:8000
```

**Note:** Custom endpoints must support vision capabilities (multimodal models) for image analysis to work.

## Project Structure

```
homebox-companion/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ homebox_companion/          # Python package
‚îÇ       ‚îú‚îÄ‚îÄ core/                   # Config, logging, exceptions
‚îÇ       ‚îú‚îÄ‚îÄ homebox/                # Homebox API client
‚îÇ       ‚îú‚îÄ‚îÄ ai/                     # OpenAI integration & prompts
‚îÇ       ‚îî‚îÄ‚îÄ tools/                  # AI tools (vision, etc.)
‚îÇ           ‚îî‚îÄ‚îÄ vision/             # Item detection & analysis
‚îú‚îÄ‚îÄ server/                         # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # App factory
‚îÇ   ‚îú‚îÄ‚îÄ api/                        # API routers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/vision.py         # Vision endpoints
‚îÇ   ‚îî‚îÄ‚îÄ schemas/                    # Pydantic models
‚îú‚îÄ‚îÄ frontend/                       # Svelte + Tailwind frontend
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ lib/                    # Stores, API client, components
‚îÇ       ‚îî‚îÄ‚îÄ routes/                 # SvelteKit pages
‚îú‚îÄ‚îÄ tests/                          # Test suite
‚îú‚îÄ‚îÄ pyproject.toml                  # Python config
‚îú‚îÄ‚îÄ Dockerfile                      # Docker build
‚îî‚îÄ‚îÄ AGENTS.md                       # AI agent guidelines
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/login` | Authenticate with Homebox |
| GET | `/api/locations` | List all locations |
| GET | `/api/locations/tree` | Get hierarchical location tree |
| GET | `/api/locations/{id}` | Get single location with children |
| POST | `/api/locations` | Create a new location |
| PUT | `/api/locations/{id}` | Update a location |
| GET | `/api/labels` | List all labels |
| POST | `/api/items` | Batch create items |
| POST | `/api/items/{id}/attachments` | Upload item attachment |
| POST | `/api/tools/vision/detect` | Detect items in a single image |
| POST | `/api/tools/vision/detect-batch` | Detect items in multiple images (parallel) |
| POST | `/api/tools/vision/analyze` | Multi-image analysis for extended details |
| POST | `/api/tools/vision/merge` | Merge multiple items using AI |
| POST | `/api/tools/vision/correct` | Correct item with user feedback |
| GET | `/api/version` | Get application version |

## Library Usage

The `homebox_companion` package can also be used as a Python library:

```python
import asyncio
from homebox_companion import detect_items_from_bytes, HomeboxClient, ItemCreate

async def main():
    # Read an image file
    with open("items.jpg", "rb") as f:
        image_bytes = f.read()

    # Detect items in the image
    items = await detect_items_from_bytes(image_bytes)
    for item in items:
        print(f"{item.name}: {item.quantity}")
        if item.manufacturer:
            print(f"  Manufacturer: {item.manufacturer}")

    # Create items in Homebox
    async with HomeboxClient() as client:
        token = await client.login("user@example.com", "password")
        locations = await client.list_locations(token)
        
        for item in items:
            item_create = ItemCreate(
                name=item.name,
                quantity=item.quantity,
                description=item.description,
                location_id=locations[0]["id"],
                label_ids=item.label_ids,
            )
            created = await client.create_item(token, item_create)
            print(f"Created: {created['name']} (ID: {created['id']})")

asyncio.run(main())
```

### Available Exports

```python
from homebox_companion import (
    # Configuration
    settings,
    
    # Client (async)
    HomeboxClient,
    ItemCreate,
    ItemUpdate,
    
    # Exceptions
    AuthenticationError,
    
    # Vision detection
    DetectedItem,
    detect_items_from_bytes,
    discriminatory_detect_items,
    
    # Advanced AI functions
    analyze_item_details_from_images,
    correct_item_with_openai,
    merge_items_with_openai,
    
    # Image utilities
    encode_image_to_data_uri,
    encode_image_bytes_to_data_uri,
)
```

## Development

### Linting

```bash
uv run ruff check .
uv run ruff format .
```

### Testing

```bash
# Run unit tests
uv run pytest

# Run integration tests (requires API keys)
uv run pytest -m integration
```

### Frontend Development

```bash
cd frontend
npm run dev      # Start dev server with hot reload
npm run build    # Production build
npm run preview  # Preview production build
```

## Contributing

Contributions are welcome! Please ensure:

1. Code passes `ruff check .`
2. Tests pass with `pytest`
3. Increment version in `pyproject.toml`
4. Update `package-lock.json` if modifying frontend dependencies

## License

MIT License - see LICENSE file for details.

## Acknowledgments

- [Homebox](https://github.com/sysadminsmedia/homebox) - The excellent home inventory system this companion is built for
- [OpenAI](https://openai.com) - For the vision AI capabilities
- [FastAPI](https://fastapi.tiangolo.com) - The modern Python web framework
- [SvelteKit](https://kit.svelte.dev) - The elegant frontend framework
- [Tailwind CSS](https://tailwindcss.com) - The utility-first CSS framework
